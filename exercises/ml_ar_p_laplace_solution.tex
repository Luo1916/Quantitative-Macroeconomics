\begin{enumerate}

\item
Computation of the conditional expectation and variance:
\begin{gather*}
E[y_{t}|y_{t-1}] = c + \phi y_{t-1}
\\
Var[y_{t}|y_{t-1}] = var(u_t) = 2
\end{gather*}
Hence the conditional density is
\begin{align*}
f_t(y_{t}|y_{t-1}; c, \phi) = \frac{1}{2} \cdot e^{-|y_{t} -(c + \phi y_{t-1})|} = \frac{1}{2} \cdot e^{-|u_t|}
\end{align*}
The conditional log-likelihood function is therefore given by
\begin{align*}
\log L(y_{2}, \dots, y_{T};c, \phi) =-(T-1) \cdot \log(2) - \sum_{t=2}^{T} |u_{t}|
\end{align*}

\item
\lstinputlisting[style=Matlab-editor,basicstyle=\mlttfamily,title=\lstname]{progs/matlab/logLikeARpLaplace.m}

\item
\lstinputlisting[style=Matlab-editor,basicstyle=\mlttfamily,title=\lstname]{progs/matlab/ARpMLLaPlace.m}
\lstinputlisting[style=Matlab-editor,basicstyle=\mlttfamily,title=\lstname]{progs/matlab/AR1MLLaPlace.m}

\item
Note that the values are very close to each other.
Maximizing the Gaussian likelihood, even though the underlying distribution is not Gaussian,
  is also known as pseudo-maximum likelihood or quasi-maximum likelihood.
It usually performs surprisingly well if you cannot pin down the underlying distribution.
\end{enumerate}