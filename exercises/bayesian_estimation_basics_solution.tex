\begin{enumerate}
\item In Quantitative Macroeconomics and Econometrics we are concerned with using data to learn about a phenomenon,
  e.g.\ the relationship between two macroeconomic variables.
That is: we want to learn about something \emph{unknown} (the parameter \(\theta \)) given something \emph{known} (the data \(y_t\)).
Let's use the sample mean as our estimating function:
\(\hat{\theta}=1/T \sum_{t=1}^T y_t\).
Due to the law of large numbers and the central limit theorem we can derive that
\(\hat{\theta}\sim N(\theta,\frac{\sigma^2}{T})\)
and conduct inference such as computing confidence intervals \([\hat{\theta}\pm 1.96 \frac{\sigma}{\sqrt{T}}]\).
\\
\textbf{Classical/Frequentist approach:} \(\theta \) is a fixed unknown quantity, that is we think there exists a \emph{true value} that is not random.
On the other hand, the estimating function, \(\hat{\theta}\), is a random variable and is evaluated via repeated sampling.
In a thought experiment, we would be able to generate a large number of datasets (given the true \(\theta \))
  and our confidence interval will contain the true value in 95\% of cases.
The estimator \(\hat{\theta}\) is \emph{best} in the sense of having the highest probability of being close to the true \(\theta \).
\\
\textbf{Bayesian approach:} \(\theta \) is treated as a \emph{random variable}; that is, there is NO true unknown value.
Instead our knowledge about the model parameter \(\theta \) is summarized by a \emph{probability distribution}.
In more detail, this distribution summarizes two sources of information:
\begin{enumerate}
\item prior information: subjective beliefs about how likely different parameter values are (information BEFORE seeing the data)
\item sample information: AFTER seeing the data, we update/revise our prior beliefs
\end{enumerate}
In a sense we explicitly make use of (subjective) probabilities to quantify uncertainty about the parameter.

\item The key ingredients are based on the rules of probability, which imply for two events \(A\) and \(B\):
  \(p(A,B)=p(A|B)p(B)\), where \(p(A,B)\) is the joint probability of both events happing simultaneously.
\(p(A|B)\) is the probability of \(A\) occurring conditional on \(B\) having occurred;
  and \(p(B)\) is the marginal probability of \(B\).
Alternatively, we can reverse \(A\) and \(B\) to get: \(p(A,B)=p(B|A)p(A)\).
Equating the two expressions gives you \textbf{Bayes' rule}:
\begin{align*}
p(B|A) = \frac{p(A|B)p(B)}{p(A)}
\end{align*}
This rule also holds for continuous variables such as parameters \(\theta \) and data \(y\):
\begin{align*}
p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)}
\end{align*}
That is, the key object of interest is the \textbf{posterior} \(p(\theta|y)\) distribution,
  which is the product of the \textbf{likelihood function} \(p(y|\theta)\) and the \textbf{prior density} \(p(\theta)\),
  divided by the \textbf{marginal data density} \(p(y)\).
In other words, the prior contains our prior (non-data) information,
  whereas the likelihood function is the density of the data conditional on the parameters.
Note that the marginal data density \(p(y)\) can be mostly ignored
  as it does not depend on the parameters
  (it is just a normalization constant as a probability density integrates to one).
Therefore, we can use the proportional \(\propto \) sign, that is the posterior is proportional to the likelihood times the prior:
\begin{align*}
p(\theta|y) \propto p(y|\theta) p(\theta)
\end{align*}
The posterior summarizes all we know about \(\theta \) after seeing the data.
It combines both data and non-data information.
The equation can be viewed as an updating rule,
  where data allows us to update our prior views about \(\theta \).

Note that Bayesians are upfront and rigorous about including non-data information!
The idea is that more information (even if subjective) tends to be better than less.

\item
In Bayesian inference, a prior distribution encodes the researcher's beliefs about parameters before observing data.
Once data is observed, Bayes' theorem is used to obtain the posterior distribution,
  which refines those beliefs by combining the prior distribution and the likelihood of the observed data.
In principle, any prior distribution can be used, but in practice, some priors are more convenient than others.
Particularly, the terms conjugate priors and natural conjugate priors refer to families of prior distributions
  that make the Bayesian updating process analytically tractable and computationally simpler.
\begin{itemize}
\item A \textbf{conjugate prior} for a given likelihood function is a prior distribution
  such that the resulting posterior distribution is in the same family of distributions as the prior.
Examples:
  \begin{itemize}
  \item Normal likelihood + \emph{Normal} prior = \emph{Normal} posterior
  \item Binomial likelihood + \emph{Beta} prior = \emph{Beta} posterior
  \item Poisson likelihood + \emph{Gamma} prior = \emph{Gamma} posterior
  \end{itemize}
\item A natural conjugate prior has the \emph{additional property} that it has the same
  functional form as the likelihood function,
  mostly within the exponential family form.
That is, the prior can be interpreted as arising from a fictitious dataset from the same data-generating process.
Examples:
  \begin{itemize}
  \item Normal-Inverse-Gamma prior for Normal Likelihood with unknown mean and unknown variance
  \item Normal-Inverse-Wishart for the Multivariate Normal Likelihood with unknown mean and unknown covariance matrix
  \end{itemize}
\end{itemize}

Why conjugate (and natural conjugate) priors matter:
\begin{itemize}
\item Ease of Computation:
While modern macroeconomics often involves complex likelihood functions derived from sophisticated structural models,
  if certain parts of the model (or approximations of it) yield standard forms for likelihood components,
  using a conjugate prior can simplify or speed up Bayesian updating.
This is helpful in large-scale models or in repeated simulations.
\item Analytical Insights:
In smaller or more stylized macro models, conjugate priors can provide closed-form posterior updates.
This can yield greater transparency in understanding how new data revise parametersâ€”valuable for policy discussions.
\item Calibration and Sensitivity:
Macroeconomists use priors informed by microeconomic evidence or past studies.
When these priors happen to fit into conjugate families, it becomes easier to see how shifting priors
  (say, in a sensitivity analysis) affects the posterior distributions.
\end{itemize}

\item The posterior is typically not analytically available and needs to be approximated
  unless for special cases using e.g.\ natural conjugate priors.
But, typically we are not interested in the exact shape of the posterior,
  but in certain statistics of the posterior distribution such as:
\begin{align*}
E[\theta|y] &= \int_{-\infty}^{\infty} \theta p(\theta|y) d\theta
\\
V[\theta|y] &= \int_{-\infty}^{\infty} \theta^2 p(\theta|y) d\theta - (E(\theta|y))^2
\end{align*}
So we only need to approximate the integrals using numerical methods such as Monte Carlo integration.
That is, IF we had iid draws from the posterior, we can make use of the law of large numbers
  and could approximate the posterior mean and variance as:
\begin{align*}
E[\theta|y] &\approx \frac{1}{S} \sum_{i=1}^S \theta_i
\\
V[\theta|y] &\approx \frac{1}{S} \sum_{i=1}^S \theta_i^2 - {\left(\frac{1}{S} \sum_{i=1}^S \theta_i\right)}^2
\end{align*}
Or in general for any function:
\begin{align*}
E[f(\theta)|y] = \int_{-\infty}^{\infty} f(\theta) p(\theta|y) d\theta \approx \frac{1}{S} \sum_{i=1}^S f(\theta_i)
\end{align*}
This is the key idea of Monte Carlo integration,
  i.e.\ replace the integral by a sum over \(S\) draws from the posterior.
The Central Limit Theorem can then be used to asses the accuracy of this approximation.
But there are two challenges:
\begin{itemize}
\item How to draw from the posterior?
\item How to make sure that the draws are iid?
\end{itemize}
The first question can be answered by using suitable \emph{posterior sampling algorithms}
  such as direct sampling, importance sampling, Metropolis-Hastings sampling, Gibbs sampling, or  Sequential Monte-Carlo sampling.
The second question is more difficult to answer and requires some knowledge about the sampling algorithm and suitable diagnostics.
\end{enumerate}